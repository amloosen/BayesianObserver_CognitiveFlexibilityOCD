{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719902b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking files in directory: data\n",
      "Found file: Table_CrypticCreaturesShiftRelative_controls_YaleCohort.csv\n",
      "Skipping file: Table_CrypticCreaturesShiftRelative_controls_YaleCohort.csv\n",
      "Found file: .DS_Store\n",
      "Skipping file: .DS_Store\n",
      "Found file: CrypticCreaturesBayesianLearner_relativeID_controls.csv\n",
      "Skipping file: CrypticCreaturesBayesianLearner_relativeID_controls.csv\n",
      "Found file: avg_confidence_deviation_plot.png\n",
      "Skipping file: avg_confidence_deviation_plot.png\n",
      "Found file: CrypticCreaturesBayesianLearner_relativeShift_OCD.csv\n",
      "Skipping file: CrypticCreaturesBayesianLearner_relativeShift_OCD.csv\n",
      "Found file: Table_CrypticCreaturesShiftRelative_YaleCohort.csv\n",
      "Skipping file: Table_CrypticCreaturesShiftRelative_YaleCohort.csv\n",
      "Found file: test.csv\n",
      "Skipping file: test.csv\n",
      "Found file: Table_CrypticCreatures_patients_YaleCohort.csv\n",
      "Skipping file: Table_CrypticCreatures_patients_YaleCohort.csv\n",
      "Found file: CrypticCreaturesBayesianLearner_relativeED.csv\n",
      "Skipping file: CrypticCreaturesBayesianLearner_relativeED.csv\n",
      "Found file: CrypticCreaturesBayesianLearner_relativeID.csv\n",
      "Skipping file: CrypticCreaturesBayesianLearner_relativeID.csv\n",
      "Found file: Table_CrypticCreatures_YaleCohort_withoutDemo.mat\n",
      "Skipping file: Table_CrypticCreatures_YaleCohort_withoutDemo.mat\n",
      "Found file: Table_CrypticCreatures_YaleCohort.csv\n",
      "Skipping file: Table_CrypticCreatures_YaleCohort.csv\n",
      "Found file: CrypticCreaturesBayesianLearner_relativeED_controls.csv\n",
      "Skipping file: CrypticCreaturesBayesianLearner_relativeED_controls.csv\n",
      "Found file: CrypticCreaturesBayesianLearner_relativeShift.csv\n",
      "Skipping file: CrypticCreaturesBayesianLearner_relativeShift.csv\n",
      "Found file: CrypticCreaturesBayesianLearner_relativeED_OCD.csv\n",
      "Skipping file: CrypticCreaturesBayesianLearner_relativeED_OCD.csv\n",
      "Found file: Table_CrypticCreatures_controls_YaleCohort.csv\n",
      "Skipping file: Table_CrypticCreatures_controls_YaleCohort.csv\n",
      "Found file: CrypticCreature_relativeShift_BayesianLearner.csv\n",
      "Skipping file: CrypticCreature_relativeShift_BayesianLearner.csv\n",
      "Found file: CrypticCreaturesBayesianLearner_relativeID_OCD.csv\n",
      "Skipping file: CrypticCreaturesBayesianLearner_relativeID_OCD.csv\n",
      "Found file: Table_CrypticCreaturesShiftRelative_patients_YaleCohort.csv\n",
      "Skipping file: Table_CrypticCreaturesShiftRelative_patients_YaleCohort.csv\n",
      "Found file: CrypticCreaturesBayesianLearner_relativeShift_controls.csv\n",
      "Skipping file: CrypticCreaturesBayesianLearner_relativeShift_controls.csv\n",
      "Found file: patients_regression_summary.csv\n",
      "Skipping file: patients_regression_summary.csv\n",
      "Found file: CrypticCreatures_BayesianLearner.csv\n",
      "Skipping file: CrypticCreatures_BayesianLearner.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "import pdb\n",
    "\n",
    "\n",
    "def read_csv_files(directory):\n",
    "    csv_files = []\n",
    "    print(f\"Checking files in directory: {directory}\")\n",
    "    for filename in os.listdir(directory):\n",
    "        print(f\"Found file: {filename}\")\n",
    "        if filename.startswith(\"sub\") and filename.endswith(\".csv\"):\n",
    "            print(f\"Reading CSV file: {filename}\")\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            csv_files.append(df)\n",
    "        else:\n",
    "            print(f\"Skipping file: {filename}\")\n",
    "    return csv_files\n",
    "\n",
    "# Set the directory path\n",
    "directory = 'data'\n",
    "\n",
    "# Call the function and get the list of dataframes\n",
    "dataframes = read_csv_files(directory)\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "for i, df in enumerate(dataframes):\n",
    "    print(f\"First few rows of DataFrame {i+1}:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2247620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory etc\n",
    "os.chdir(\"data\")\n",
    "\n",
    "# Load data\n",
    "CrypticCreatures = pd.read_csv(\"Table_CrypticCreatures_YaleCohort.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac46de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function to dynamically initialize a matrix based on the task ID and characteristics\n",
    "def initialize_matrix(task_id):\n",
    "    if task_id == 1:\n",
    "        num_dimensions = 2\n",
    "        variants_per_dimension = 2\n",
    "    elif task_id == 2:\n",
    "        # Tasks 1 and 2 have 4 dimensions, each with 2 variations\n",
    "        num_dimensions = 4\n",
    "        variants_per_dimension = 2\n",
    "    elif task_id == 3:\n",
    "        # Task 3 has 4 dimensions, each with 3 variations\n",
    "        num_dimensions = 4\n",
    "        variants_per_dimension = 3\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported task ID\")\n",
    "\n",
    "    # Calculate the size of the matrix\n",
    "    matrix_size = variants_per_dimension ** num_dimensions\n",
    "\n",
    "    # Initialize the matrix with equal probabilities\n",
    "    matrix = np.full((matrix_size,), 1 / matrix_size)\n",
    "\n",
    "    # Reshape the matrix into a hypercube based on the number of dimensions\n",
    "    matrix = matrix.reshape([variants_per_dimension] * num_dimensions)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "# 2. Merged function to identify differing dimensions and create the feature matrix\n",
    "def identify_and_create_feature_matrix(row):\n",
    "    differing_dimensions = []\n",
    "    dimensions = ['color', 'hair', 'eyes', 'bumpiness']  # Assuming these are the dimensions\n",
    "    feature_matrix = {}\n",
    "\n",
    "    for dim in dimensions:\n",
    "        stim1_feature = row[f'stim1_{dim}']\n",
    "        stim2_feature = row[f'stim2_{dim}']\n",
    "\n",
    "        if stim1_feature != stim2_feature:\n",
    "            differing_dimensions.append(dim)\n",
    "            # Sort the features so that the higher value is always in the first row\n",
    "            sorted_features = sorted([stim1_feature, stim2_feature], reverse=True)\n",
    "            feature_matrix[dim] = sorted_features\n",
    "\n",
    "    feature_matrix_df = pd.DataFrame(feature_matrix)\n",
    "    return differing_dimensions, feature_matrix_df\n",
    "\n",
    "# 3. Function to map chosen stimulus' features onto the initialised feature matrix\n",
    "def map_features_to_standardized_matrix(stim_features, feature_matrix):\n",
    "    mapped_cells = []\n",
    "    for dim in feature_matrix.columns:\n",
    "        stim_value = stim_features[dim]\n",
    "        row_index = None\n",
    "        col_index = None\n",
    "\n",
    "        # Iterate over the feature matrix to find where the stim_value matches\n",
    "        for i in range(len(feature_matrix)):\n",
    "            if feature_matrix.at[i, dim] == stim_value:\n",
    "                # Find the row (i) and column (j) where the feature matches in the matrix\n",
    "                row_index = i\n",
    "                col_index = feature_matrix.columns.get_loc(dim)\n",
    "                break\n",
    "\n",
    "        if row_index is not None and col_index is not None:\n",
    "            # Assuming each dimension and feature has a corresponding mapped cell\n",
    "            mapped_cells.append((row_index, col_index))\n",
    "        else:\n",
    "            print(f\"Warning: Could not find matching row/column for feature {stim_value} in dimension {dim}.\")\n",
    "\n",
    "    # Create a matrix based on the mapped_cells\n",
    "    matrix_size = len(feature_matrix)  # Assuming a square matrix based on the number of features\n",
    "    mapped_matrix = np.zeros((matrix_size, matrix_size))\n",
    "\n",
    "    for (i, j) in mapped_cells:\n",
    "        mapped_matrix[i, j] = 1\n",
    "\n",
    "    # Return both mapped_cells and the newly created matrix\n",
    "    return mapped_cells, mapped_matrix\n",
    "\n",
    "# 4. Function to calculate entropy of the probability matrix\n",
    "def calculate_entropy(matrix):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a given probability matrix.\n",
    "    \n",
    "    Entropy is a measure of uncertainty or randomness in the probability distribution.\n",
    "    A high entropy value indicates a more uniform distribution (high uncertainty), \n",
    "    while a low entropy value indicates a more concentrated distribution (low uncertainty).\n",
    "\n",
    "    Parameters:\n",
    "    - matrix: A 2D numpy array representing the probability matrix.\n",
    "\n",
    "    Returns:\n",
    "    - entropy: The calculated entropy value for the matrix.\n",
    "    \"\"\"\n",
    "    # Flatten the matrix to a 1D array of probabilities\n",
    "    probabilities = matrix.flatten()\n",
    "    # Filter out zero probabilities to avoid log(0) which is undefined\n",
    "    probabilities = probabilities[probabilities > 0]\n",
    "    # Calculate entropy using the formula: H = -sum(p * log2(p))\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4db8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_matrix(matrix, chosen_matrix, feedback):\n",
    "    \"\"\"\n",
    "    Update the probability matrix based on feedback regarding whether the chosen stimulus entailed the correct feature.\n",
    "    \n",
    "    This function adjusts the probability distribution within the matrix by setting certain cells to zero based on feedback, \n",
    "    while ensuring that cells already set to zero remain unaffected. After updating, the matrix is normalized so that \n",
    "    the sum of all probabilities remains equal to 1.\n",
    "\n",
    "    Matrix Structure:\n",
    "    The matrix represents combinations of two dimensions, each with two possible features:\n",
    "    \n",
    "          D2F1  | D2F2\n",
    "        ----------------\n",
    "    D1F1 |  [0, 0]\n",
    "    D1F2 |  [0, 0]\n",
    "    \n",
    "    Parameters:\n",
    "    - matrix: 2x2 numpy array representing the current probability matrix.\n",
    "    - chosen_matrix: A 2x2 numpy array indicating the chosen feature combinations with 1s, and non-chosen combinations with 0s.\n",
    "    - feedback: Boolean indicating whether the chosen feature combination was correct (True) or incorrect (False).\n",
    "    \n",
    "    Process:\n",
    "    1. The function creates a mask to identify non-zero cells in the current matrix.\n",
    "    2. If feedback is positive (True):\n",
    "       - The function sets to zero the cells where `chosen_matrix` has a 1 and the corresponding cell in `matrix` is non-zero.\n",
    "    3. If feedback is negative (False):\n",
    "       - The function sets to zero the cells where `chosen_matrix` has a 0 and the corresponding cell in `matrix` is non-zero.\n",
    "    4. The function then normalizes the matrix so that the sum of all elements equals 1.\n",
    "    \n",
    "    Returns:\n",
    "    - The updated and normalized probability matrix.\n",
    "    \"\"\"\n",
    " \n",
    "   # Create a mask for non-zero values in the matrix\n",
    "    non_zero_mask = matrix != 0\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    # Update the matrix based on the feedback condition and non-zero values\n",
    "    if feedback:\n",
    "        # Set cells to zero where chosen_matrix has a 0 and matrix is non-zero\n",
    "        matrix[(chosen_matrix == 0) & non_zero_mask] = 0\n",
    "    else:\n",
    "        # Set cells to zero where chosen_matrix has a 1 and matrix is non-zero\n",
    "        matrix[(chosen_matrix == 1) & non_zero_mask] = 0\n",
    "\n",
    "    # Normalize the matrix so that the sum of all elements equals 1\n",
    "    matrix_sum = np.sum(matrix)\n",
    "    if matrix_sum > 0:\n",
    "        matrix = matrix / matrix_sum\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c128c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51be8e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_first_participant(CrypticCreatures, id_tested, task_id_tested):\n",
    "    participant_data = CrypticCreatures[(CrypticCreatures['id'] == id_tested) & (CrypticCreatures['task_id'] == task_id_tested)]\n",
    "    first_trial_row = participant_data.iloc[0]\n",
    "    \n",
    "    prob_matrix = initialize_matrix(task_id_tested)\n",
    "\n",
    "    for index, row in participant_data.iterrows():\n",
    "        # Initialise shift specific variables if it's the first trial or a rule change\n",
    "        if row['trial'] == 1:\n",
    "            differing_dimensions, feature_matrix = identify_and_create_feature_matrix(first_trial_row)\n",
    "            \n",
    "        if row['ruleChange'] == 1:\n",
    "                pdb.set_trace()\n",
    "                shift_matrix = feature_matrix.copy()\n",
    "                print(f\"Shift detected at Trial {row['trial']}. Storing matrix:\")\n",
    "                print(shift_matrix)\n",
    "                feature_matrix = pd.DataFrame()\n",
    "                differing_dimensions, feature_matrix = identify_and_create_feature_matrix(first_trial_row)\n",
    "            \n",
    "        # The rest of the code continues here\n",
    "        chosen_stimulus = int(row['response'])\n",
    "        stim_features = {dim: row[f'stim{chosen_stimulus}_{dim}'] for dim in differing_dimensions}\n",
    "\n",
    "        print(f\"\\nProcessing Trial {row['trial']} (Shift: {row['ruleChange'] == 1})\")\n",
    "        print(f\"Feature Matrix: {feature_matrix}\")\n",
    "        print(f\"Chosen Stimulus: {chosen_stimulus}\")\n",
    "        print(f\"Feedback: {row['chosen_outcome']}\")\n",
    "        print(f\"Stimulus Features: {stim_features}\")\n",
    "        print(f\"Differing Dimensions: {differing_dimensions}\")\n",
    "        \n",
    "        # Generate mapped cells in the required format\n",
    "        mapped_cells, mapped_matrix = map_features_to_standardized_matrix(stim_features, feature_matrix)\n",
    "        print(f\"Mapped Matrix: {mapped_matrix}\")\n",
    "\n",
    "        # Convert feedback to boolean\n",
    "        feedback = bool(row['chosen_outcome'])\n",
    "        \n",
    "        \n",
    "\n",
    "        # Call update_matrix with correctly formatted inputs\n",
    "        prob_matrix = update_matrix(prob_matrix, mapped_matrix, feedback)\n",
    "        entropy = calculate_entropy(prob_matrix)\n",
    "        \n",
    "        print(f\"Updated Probability Matrix after Trial {row['trial']}:\")\n",
    "        print(f\"Prob Matrix:{prob_matrix}\")\n",
    "        print(f\"Entropy: {entropy}\")\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a306f189",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'stim1_color'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stim1_color'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m process_first_participant(CrypticCreatures, id_tested\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, task_id_tested\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mprocess_first_participant\u001b[0;34m(CrypticCreatures, id_tested, task_id_tested)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m participant_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Initialise shift specific variables if it's the first trial or a rule change\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrial\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m         differing_dimensions, feature_matrix \u001b[38;5;241m=\u001b[39m identify_and_create_feature_matrix(first_trial_row)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruleChange\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     13\u001b[0m             pdb\u001b[38;5;241m.\u001b[39mset_trace()\n",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m, in \u001b[0;36midentify_and_create_feature_matrix\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     32\u001b[0m feature_matrix \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m dimensions:\n\u001b[0;32m---> 35\u001b[0m     stim1_feature \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstim1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     36\u001b[0m     stim2_feature \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstim2_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stim1_feature \u001b[38;5;241m!=\u001b[39m stim2_feature:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stim1_color'"
     ]
    }
   ],
   "source": [
    "process_first_participant(CrypticCreatures, id_tested=4, task_id_tested=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad46848",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CrypticCreatures['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd69f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulations and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb6e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through the first participant's trials and understand their structure\n",
    "def process_first_participant_test(CrypticCreatures, id_tested, task_id_tested):\n",
    "    # Filter the data for the first participant and task 1\n",
    "    participant_data = CrypticCreatures[(CrypticCreatures['id'] == id_tested) & (CrypticCreatures['task_id'] == task_id_tested)]\n",
    "    \n",
    "    previous_trial_features = None\n",
    "    \n",
    "    for index, row in participant_data.iterrows():\n",
    "        trial_number = row['trial']\n",
    "        correctness = row['chosen_outcome']  # Assuming 1 for correct, 0 for incorrect\n",
    "        chosen_stimulus = row['response']\n",
    "        \n",
    "        # Extract the features of stimuli 1 and 2\n",
    "        stim1_features = {\n",
    "            'color': row['stim1_color'],\n",
    "            'hair': row['stim1_hair'],\n",
    "            'eyes': row['stim1_eyes'],\n",
    "            'bumpiness': row['stim1_bumpiness']\n",
    "        }\n",
    "        \n",
    "        stim2_features = {\n",
    "            'color': row['stim2_color'],\n",
    "            'hair': row['stim2_hair'],\n",
    "            'eyes': row['stim2_eyes'],\n",
    "            'bumpiness': row['stim2_bumpiness']\n",
    "        }\n",
    "        \n",
    "        # Filter only the dimensions where there is a difference\n",
    "        differing_dimensions = identify_differing_dimensions(row)\n",
    "        feature_matrix = create_feature_matrix(stim1_features, stim2_features, differing_dimensions)\n",
    "        print(f\"\\nTrial {trial_number}\")\n",
    "        print(f\"Correctness: {correctness}\")\n",
    "        print(f\"Chosen Stimulus: {chosen_stimulus}\")\n",
    "        print(f\"Stimulus 1: {stim1_features}\")\n",
    "        print(f\"Stimulus 2: {stim2_features}\")\n",
    "        print(\"Dimension Differences Matrix:\")\n",
    "        print(feature_matrix)\n",
    "        \n",
    "        # Compare the feature values with the previous trial\n",
    "        if previous_trial_features is not None:\n",
    "            same_features = feature_matrix.equals(previous_trial_features)\n",
    "            print(f\"Feature values remained the same as the previous trial: {same_features}\")\n",
    "        else:\n",
    "            print(\"No previous trial to compare.\")\n",
    "        \n",
    "        # Update previous trial features\n",
    "        previous_trial_features = feature_matrix.copy()\n",
    "        \n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Assuming CrypticCreatures is your DataFrame\n",
    "# Replace this with the actual DataFrame loading code\n",
    "# CrypticCreatures = pd.read_csv('your_data_file.csv')\n",
    "# Process the first participant\n",
    "id_tested = 2\n",
    "task_id_tested = 1\n",
    "process_first_participant_test(CrypticCreatures,id_tested,task_id_tested)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stimulate/check function \n",
    "trials = [  # Trial 1: choose cells (0, 1) and (1, 0), feedback is negative\n",
    "    ([(0, 1), (0, 1)], False,\n",
    "    [(1, 0), (0, 1)], True) # Trial 3: choose cells (0, 1) and (1, 0), feedback is positive\n",
    "]\n",
    "prob_matrix = initialize_matrix(1)\n",
    "# Iterate through each trial and update the matrix\n",
    "for i, (chosen_cells, feedback) in enumerate(trials):\n",
    "    print(f\"Trial {i+1}:\")\n",
    "    print(\"Before update:\")\n",
    "    print(prob_matrix)\n",
    "    \n",
    "    # Update the matrix based on the feedback for this trial\n",
    "    prob_matrix = update_matrix(prob_matrix, chosen_cells, feedback)\n",
    "    \n",
    "    print(\"After update:\")\n",
    "    print(prob_matrix)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Final matrix after all trials\n",
    "print(\"Final matrix after all trials:\")\n",
    "print(prob_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fcf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
